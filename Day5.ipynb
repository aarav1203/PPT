{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Setting up a Kafka Producer:\n",
        "   a) Write a Python program to create a Kafka producer.\n",
        "\n"
      ],
      "metadata": {
        "id": "nns9so3l5wMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Producer\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def delivery_report(err, msg):\n",
        "    \"\"\"Callback function called once the message is delivered or delivery failed.\"\"\"\n",
        "    if err is not None:\n",
        "        print(f'Message delivery failed: {err}')\n",
        "    else:\n",
        "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
        "\n",
        "def create_kafka_producer():\n",
        "    \"\"\"Create a Kafka producer with the specified bootstrap servers.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers\n",
        "    }\n",
        "    producer = Producer(config)\n",
        "    return producer\n",
        "\n",
        "def produce_messages(producer, messages):\n",
        "    \"\"\"Produce messages to the specified Kafka topic.\"\"\"\n",
        "    for message in messages:\n",
        "        producer.produce(topic, message, callback=delivery_report)\n",
        "    # Wait for any outstanding messages to be delivered\n",
        "    producer.flush()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka producer\n",
        "    kafka_producer = create_kafka_producer()\n",
        "\n",
        "    # Define the messages to be produced\n",
        "    messages = [\n",
        "        'Hello Kafka!',\n",
        "        'This is a test message.',\n",
        "        'Another message.',\n",
        "    ]\n",
        "\n",
        "    # Produce the messages\n",
        "    produce_messages(kafka_producer, messages)\n",
        "\n",
        "    # Close the Kafka producer\n",
        "    kafka_producer.close()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "XTIZY2DD5-AN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3fbpgVvF5vbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   b) Configure the producer to connect to a Kafka cluster.\n",
        "\n"
      ],
      "metadata": {
        "id": "-Amu8rW_6EoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Producer\n",
        "\n",
        "# Kafka cluster configuration\n",
        "bootstrap_servers = 'kafka1:9092,kafka2:9092,kafka3:9092'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def delivery_report(err, msg):\n",
        "    \"\"\"Callback function called once the message is delivered or delivery failed.\"\"\"\n",
        "    if err is not None:\n",
        "        print(f'Message delivery failed: {err}')\n",
        "    else:\n",
        "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
        "\n",
        "def create_kafka_producer():\n",
        "    \"\"\"Create a Kafka producer with the specified bootstrap servers.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers\n",
        "    }\n",
        "    producer = Producer(config)\n",
        "    return producer\n",
        "\n",
        "def produce_messages(producer, messages):\n",
        "    \"\"\"Produce messages to the specified Kafka topic.\"\"\"\n",
        "    for message in messages:\n",
        "        producer.produce(topic, message, callback=delivery_report)\n",
        "    # Wait for any outstanding messages to be delivered\n",
        "    producer.flush()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka producer\n",
        "    kafka_producer = create_kafka_producer()\n",
        "\n",
        "    # Define the messages to be produced\n",
        "    messages = [\n",
        "        'Hello Kafka!',\n",
        "        'This is a test message.',\n",
        "        'Another message.',\n",
        "    ]\n",
        "\n",
        "    # Produce the messages\n",
        "    produce_messages(kafka_producer, messages)\n",
        "\n",
        "    # Close the Kafka producer\n",
        "    kafka_producer.close()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "g4BnjZHf6wIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   c) Implement logic to send messages to a Kafka topic."
      ],
      "metadata": {
        "id": "xZQjMl4A68iW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Producer\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def delivery_report(err, msg):\n",
        "    \"\"\"Callback function called once the message is delivered or delivery failed.\"\"\"\n",
        "    if err is not None:\n",
        "        print(f'Message delivery failed: {err}')\n",
        "    else:\n",
        "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
        "\n",
        "def create_kafka_producer():\n",
        "    \"\"\"Create a Kafka producer with the specified bootstrap servers.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers\n",
        "    }\n",
        "    producer = Producer(config)\n",
        "    return producer\n",
        "\n",
        "def produce_messages(producer, messages):\n",
        "    \"\"\"Produce messages to the specified Kafka topic.\"\"\"\n",
        "    for message in messages:\n",
        "        producer.produce(topic, message.encode('utf-8'), callback=delivery_report)\n",
        "    # Wait for any outstanding messages to be delivered\n",
        "    producer.flush()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka producer\n",
        "    kafka_producer = create_kafka_producer()\n",
        "\n",
        "    # Define the messages to be produced\n",
        "    messages = [\n",
        "        'Hello Kafka!',\n",
        "        'This is a test message.',\n",
        "        'Another message.',\n",
        "    ]\n",
        "\n",
        "    # Produce the messages\n",
        "    produce_messages(kafka_producer, messages)\n",
        "\n",
        "    # Close the Kafka producer\n",
        "    kafka_producer.close()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PQOST3b-7zxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Setting up a Kafka Consumer:\n",
        "   a) Write a Python program to create a Kafka consumer.\n"
      ],
      "metadata": {
        "id": "Dutk3YzS8EA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Consumer, KafkaException\n",
        "from confluent_kafka.admin import AdminClient, NewTopic\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "group_id = 'my_consumer_group'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def create_kafka_consumer():\n",
        "    \"\"\"Create a Kafka consumer with the specified bootstrap servers and group ID.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers,\n",
        "        'group.id': group_id\n",
        "    }\n",
        "    consumer = Consumer(config)\n",
        "    return consumer\n",
        "\n",
        "def subscribe_to_topic(consumer):\n",
        "    \"\"\"Subscribe to the specified Kafka topic.\"\"\"\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "def consume_messages(consumer):\n",
        "    \"\"\"Consume messages from the subscribed Kafka topic.\"\"\"\n",
        "    try:\n",
        "        while True:\n",
        "            msg = consumer.poll(1.0)  # Poll for new messages\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaException._PARTITION_EOF:\n",
        "                    # End of partition reached, continue polling\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f'Error occurred: {msg.error().str()}')\n",
        "                    break\n",
        "            else:\n",
        "                # Process the received message\n",
        "                print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "        # Close the Kafka consumer\n",
        "        consumer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka consumer\n",
        "    kafka_consumer = create_kafka_consumer()\n",
        "\n",
        "    # Subscribe to the Kafka topic\n",
        "    subscribe_to_topic(kafka_consumer)\n",
        "\n",
        "    # Consume messages from the topic\n",
        "    consume_messages(kafka_consumer)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "z_i3QEQl8JDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   b) Configure the consumer to connect to a Kafka cluster."
      ],
      "metadata": {
        "id": "caaq0FJK8RW0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Consumer, KafkaException\n",
        "from confluent_kafka.admin import AdminClient, NewTopic\n",
        "\n",
        "# Kafka cluster configuration\n",
        "bootstrap_servers = 'kafka1:9092,kafka2:9092,kafka3:9092'\n",
        "group_id = 'my_consumer_group'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def create_kafka_consumer():\n",
        "    \"\"\"Create a Kafka consumer with the specified bootstrap servers and group ID.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers,\n",
        "        'group.id': group_id\n",
        "    }\n",
        "    consumer = Consumer(config)\n",
        "    return consumer\n",
        "\n",
        "def subscribe_to_topic(consumer):\n",
        "    \"\"\"Subscribe to the specified Kafka topic.\"\"\"\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "def consume_messages(consumer):\n",
        "    \"\"\"Consume messages from the subscribed Kafka topic.\"\"\"\n",
        "    try:\n",
        "        while True:\n",
        "            msg = consumer.poll(1.0)  # Poll for new messages\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaException._PARTITION_EOF:\n",
        "                    # End of partition reached, continue polling\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f'Error occurred: {msg.error().str()}')\n",
        "                    break\n",
        "            else:\n",
        "                # Process the received message\n",
        "                print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "        # Close the Kafka consumer\n",
        "        consumer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka consumer\n",
        "    kafka_consumer = create_kafka_consumer()\n",
        "\n",
        "    # Subscribe to the Kafka topic\n",
        "    subscribe_to_topic(kafka_consumer)\n",
        "\n",
        "    # Consume messages from the topic\n",
        "    consume_messages(kafka_consumer)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6T5iu-GU8mHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   c) Implement logic to consume messages from a Kafka topic."
      ],
      "metadata": {
        "id": "-71SVKbH80aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Consumer, KafkaException\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "group_id = 'my_consumer_group'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def create_kafka_consumer():\n",
        "    \"\"\"Create a Kafka consumer with the specified bootstrap servers and group ID.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers,\n",
        "        'group.id': group_id\n",
        "    }\n",
        "    consumer = Consumer(config)\n",
        "    return consumer\n",
        "\n",
        "def subscribe_to_topic(consumer):\n",
        "    \"\"\"Subscribe to the specified Kafka topic.\"\"\"\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "def consume_messages(consumer):\n",
        "    \"\"\"Consume messages from the subscribed Kafka topic.\"\"\"\n",
        "    try:\n",
        "        while True:\n",
        "            msg = consumer.poll(1.0)  # Poll for new messages\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaException._PARTITION_EOF:\n",
        "                    # End of partition reached, continue polling\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f'Error occurred: {msg.error().str()}')\n",
        "                    break\n",
        "            else:\n",
        "                # Process the received message\n",
        "                print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "        # Close the Kafka consumer\n",
        "        consumer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka consumer\n",
        "    kafka_consumer = create_kafka_consumer()\n",
        "\n",
        "    # Subscribe to the Kafka topic\n",
        "    subscribe_to_topic(kafka_consumer)\n",
        "\n",
        "    # Consume messages from the topic\n",
        "    consume_messages(kafka_consumer)\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vFfhZKU09WgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Creating and Managing Kafka Topics\n",
        "\n",
        "  a) Write a Python program to create a new Kafka topic.\n"
      ],
      "metadata": {
        "id": "yO1ECKLO9lwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka.admin import AdminClient, NewTopic\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "\n",
        "def create_topic(topic_name, num_partitions, replication_factor):\n",
        "    \"\"\"Create a new Kafka topic.\"\"\"\n",
        "    # Configure the admin client\n",
        "    admin_client = AdminClient({'bootstrap.servers': bootstrap_servers})\n",
        "\n",
        "    # Create a NewTopic object with the topic configuration\n",
        "    new_topic = NewTopic(\n",
        "        topic=topic_name,\n",
        "        num_partitions=num_partitions,\n",
        "        replication_factor=replication_factor\n",
        "    )\n",
        "\n",
        "    # Create the topic\n",
        "    admin_client.create_topics([new_topic])\n",
        "\n",
        "    # Close the admin client\n",
        "    admin_client.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Define the topic configuration\n",
        "    topic_name = 'my_topic'\n",
        "    num_partitions = 3\n",
        "    replication_factor = 1\n",
        "\n",
        "    # Create the Kafka topic\n",
        "    create_topic(topic_name, num_partitions, replication_factor)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YuYHE2yc-AL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   b) Implement functionality to list existing topics.\n",
        "\n"
      ],
      "metadata": {
        "id": "1Ql19H65-KL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka.admin import AdminClient\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "\n",
        "def list_topics():\n",
        "    \"\"\"List the existing Kafka topics.\"\"\"\n",
        "    # Configure the admin client\n",
        "    admin_client = AdminClient({'bootstrap.servers': bootstrap_servers})\n",
        "\n",
        "    # Get the metadata for all topics\n",
        "    metadata = admin_client.list_topics(timeout=5)\n",
        "\n",
        "    # Extract the topic names from the metadata\n",
        "    topic_names = list(metadata.topics.keys())\n",
        "\n",
        "    # Close the admin client\n",
        "    admin_client.close()\n",
        "\n",
        "    # Return the list of topic names\n",
        "    return topic_names\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # List the Kafka topics\n",
        "    topics = list_topics()\n",
        "\n",
        "    # Print the topic names\n",
        "    for topic in topics:\n",
        "        print(topic)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ycE6smoX-YJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   c) Develop logic to delete an existing Kafka topic."
      ],
      "metadata": {
        "id": "issih9IS-eEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka.admin import AdminClient\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "\n",
        "def delete_topic(topic_name):\n",
        "    \"\"\"Delete an existing Kafka topic.\"\"\"\n",
        "    # Configure the admin client\n",
        "    admin_client = AdminClient({'bootstrap.servers': bootstrap_servers})\n",
        "\n",
        "    # Delete the topic\n",
        "    admin_client.delete_topics([topic_name], operation_timeout=30)\n",
        "\n",
        "    # Close the admin client\n",
        "    admin_client.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Specify the topic to delete\n",
        "    topic_name = 'my_topic'\n",
        "\n",
        "    # Delete the Kafka topic\n",
        "    delete_topic(topic_name)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "MxOP7KuV-x5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Producing and Consuming Messages:\n",
        "\n",
        "   a) Write a Python program to produce messages to a Kafka topic.\n"
      ],
      "metadata": {
        "id": "6Lf78yni_CxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Producer\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def delivery_report(err, msg):\n",
        "    \"\"\"Callback function called once the message is delivered or delivery failed.\"\"\"\n",
        "    if err is not None:\n",
        "        print(f'Message delivery failed: {err}')\n",
        "    else:\n",
        "        print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
        "\n",
        "def create_kafka_producer():\n",
        "    \"\"\"Create a Kafka producer with the specified bootstrap servers.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers\n",
        "    }\n",
        "    producer = Producer(config)\n",
        "    return producer\n",
        "\n",
        "def produce_messages(producer, messages):\n",
        "    \"\"\"Produce messages to the specified Kafka topic.\"\"\"\n",
        "    for message in messages:\n",
        "        producer.produce(topic, message, callback=delivery_report)\n",
        "    # Wait for any outstanding messages to be delivered\n",
        "    producer.flush()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka producer\n",
        "    kafka_producer = create_kafka_producer()\n",
        "\n",
        "    # Define the messages to be produced\n",
        "    messages = [\n",
        "        'Hello Kafka!',\n",
        "        'This is a test message.',\n",
        "        'Another message.',\n",
        "    ]\n",
        "\n",
        "    # Produce the messages\n",
        "    produce_messages(kafka_producer, messages)\n",
        "\n",
        "    # Close the Kafka producer\n",
        "    kafka_producer.close()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "yX00jhCI_rr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Consumer, KafkaException\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "group_id = 'my_consumer_group'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def create_kafka_consumer():\n",
        "    \"\"\"Create a Kafka consumer with the specified bootstrap servers and group ID.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers,\n",
        "        'group.id': group_id\n",
        "    }\n",
        "    consumer = Consumer(config)\n",
        "    return consumer\n",
        "\n",
        "def subscribe_to_topic(consumer):\n",
        "    \"\"\"Subscribe to the specified Kafka topic.\"\"\"\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "def consume_messages(consumer):\n",
        "    \"\"\"Consume messages from the subscribed Kafka topic.\"\"\"\n",
        "    try:\n",
        "        while True:\n",
        "            msg = consumer.poll(1.0)  # Poll for new messages\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaException._PARTITION_EOF:\n",
        "                    # End of partition reached, continue polling\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f'Error occurred: {msg.error().str()}')\n",
        "                    break\n",
        "            else:\n",
        "                # Process the received message\n",
        "                print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "        # Close the Kafka consumer\n",
        "        consumer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka consumer\n",
        "    kafka_consumer = create_kafka_consumer()\n",
        "\n",
        "    # Subscribe to the Kafka topic\n",
        "    subscribe_to_topic(kafka_consumer)\n",
        "\n",
        "    # Consume messages from the topic\n",
        "    consume_messages(kafka_consumer)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "MJXVYZjzADO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   c) Test the end-to-end flow of message production and consumption."
      ],
      "metadata": {
        "id": "etNg6XQ6AMDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test the end-to-end flow of message production and consumption, you need to run both the producer and consumer programs simultaneously. Here's an example of how you can test the flow:\n",
        "\n",
        "1. Run the Kafka producer program in one terminal or command prompt window:\n",
        "\n",
        "\n",
        "```\n",
        "python kafka_producer.py\n",
        "```\n",
        "\n",
        "2.In another terminal or command prompt window, run the Kafka consumer program:\n",
        "\n",
        "```\n",
        "python kafka_consumer.py\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mjFBVv3DAZRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Working with Kafka Consumer Groups:\n",
        "\n",
        "   a) Write a Python program to create a Kafka consumer within a consumer group.\n"
      ],
      "metadata": {
        "id": "UZWisTjtA9fK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Consumer, KafkaException\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "group_id = 'my_consumer_group'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def create_kafka_consumer():\n",
        "    \"\"\"Create a Kafka consumer with the specified bootstrap servers and group ID.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers,\n",
        "        'group.id': group_id,\n",
        "        'auto.offset.reset': 'earliest'  # Start consuming from the beginning of the topic\n",
        "    }\n",
        "    consumer = Consumer(config)\n",
        "    return consumer\n",
        "\n",
        "def subscribe_to_topic(consumer):\n",
        "    \"\"\"Subscribe to the specified Kafka topic.\"\"\"\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "def consume_messages(consumer):\n",
        "    \"\"\"Consume messages from the subscribed Kafka topic.\"\"\"\n",
        "    try:\n",
        "        while True:\n",
        "            msg = consumer.poll(1.0)  # Poll for new messages\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaException._PARTITION_EOF:\n",
        "                    # End of partition reached, continue polling\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f'Error occurred: {msg.error().str()}')\n",
        "                    break\n",
        "            else:\n",
        "                # Process the received message\n",
        "                print(f'Received message: {msg.value().decode(\"utf-8\")}')\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "        # Close the Kafka consumer\n",
        "        consumer.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka consumer\n",
        "    kafka_consumer = create_kafka_consumer()\n",
        "\n",
        "    # Subscribe to the Kafka topic\n",
        "    subscribe_to_topic(kafka_consumer)\n",
        "\n",
        "    # Consume messages from the topic\n",
        "    consume_messages(kafka_consumer)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "8rQTF7RKBDHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " b) Implement logic to handle messages consumed by different consumers within the same group.\n"
      ],
      "metadata": {
        "id": "4mUJf9xUBICH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from confluent_kafka import Consumer, KafkaException\n",
        "\n",
        "# Kafka broker configuration\n",
        "bootstrap_servers = 'localhost:9092'\n",
        "group_id = 'my_consumer_group'\n",
        "topic = 'my_topic'\n",
        "\n",
        "def create_kafka_consumer():\n",
        "    \"\"\"Create a Kafka consumer with the specified bootstrap servers and group ID.\"\"\"\n",
        "    config = {\n",
        "        'bootstrap.servers': bootstrap_servers,\n",
        "        'group.id': group_id,\n",
        "        'auto.offset.reset': 'earliest'  # Start consuming from the beginning of the topic\n",
        "    }\n",
        "    consumer = Consumer(config)\n",
        "    return consumer\n",
        "\n",
        "def subscribe_to_topic(consumer):\n",
        "    \"\"\"Subscribe to the specified Kafka topic.\"\"\"\n",
        "    consumer.subscribe([topic])\n",
        "\n",
        "def consume_messages(consumer):\n",
        "    \"\"\"Consume messages from the subscribed Kafka topic.\"\"\"\n",
        "    try:\n",
        "        while True:\n",
        "            msg = consumer.poll(1.0)  # Poll for new messages\n",
        "            if msg is None:\n",
        "                continue\n",
        "            if msg.error():\n",
        "                if msg.error().code() == KafkaException._PARTITION_EOF:\n",
        "                    # End of partition reached, continue polling\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f'Error occurred: {msg.error().str()}')\n",
        "                    break\n",
        "            else:\n",
        "                # Process the received message\n",
        "                process_message(msg)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    finally:\n",
        "        # Close the Kafka consumer\n",
        "        consumer.close()\n",
        "\n",
        "def process_message(msg):\n",
        "    \"\"\"Process the received message.\"\"\"\n",
        "    partition = msg.partition()\n",
        "    offset = msg.offset()\n",
        "    value = msg.value().decode('utf-8')\n",
        "    print(f'Received message: Partition={partition}, Offset={offset}, Value={value}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a Kafka consumer\n",
        "    kafka_consumer = create_kafka_consumer()\n",
        "\n",
        "    # Subscribe to the Kafka topic\n",
        "    subscribe_to_topic(kafka_consumer)\n",
        "\n",
        "    # Consume messages from the topic\n",
        "    consume_messages(kafka_consumer)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "j4uwA58qBTrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Observe the behavior of consumer group rebalancing when adding or removing consumers."
      ],
      "metadata": {
        "id": "eCpV6hvhBZJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you add or remove consumers within a consumer group, Kafka performs a process called \"consumer group rebalancing\" to redistribute the partitions among the consumers. This ensures an even distribution of partitions and load across the consumers within the group. Let's observe the behavior of consumer group rebalancing by performing the following steps:\n",
        "\n",
        "1.Start the consumer program with a single consumer within the consumer group:\n",
        "\n",
        "```\n",
        "python kafka_consumer.py\n",
        "```\n",
        "2.While the consumer is running, start another instance of the consumer program in a new terminal or command prompt window:\n",
        "\n",
        "\n",
        "```\n",
        "python kafka_consumer.py\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LCu1lPtpBoi1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwT0_ADZAK5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yZG-L7t6Jxu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}